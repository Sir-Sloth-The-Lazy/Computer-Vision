# -*- coding: utf-8 -*-
"""Deep_Neural_Nets_imageClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z662WFK79rPzBFCoaFEiY-bSCWVS_mpb
"""

!pip install wandb

!wandb login

import wandb
from wandb.integration.keras import WandbMetricsLogger
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow import keras

sweep_config = {

    'method' : 'grid',
    'metric' : {
        'name': 'val_accuracy',
        'goal': 'maximize'
                },
    'parameters' : {
        'batch_size': {'values': [8,16]},
        'learning_rate': {'values': [0.001,0.0001]},
        'hidden_nodes': {'values': [128,64]},
        'img_size': {'values': [16, 224]},
        'epochs': {'values': [5,10]}
    }
}

sweep_id = wandb.sweep(sweep_config, project='5_flowers_experiment')

import tensorflow as tf
from tensorflow import keras
import wandb
from wandb.integration.keras import WandbMetricsLogger

def train():
  with wandb.init() as run:
    config = wandb.config

    IMG_HEIGHT = config.img_size
    IMG_WIDTH = config.img_size
    IMG_CHANNELS = 3
    CLASS_NAMES = ["daisy" , "dandelion" , "roses" , "sunflowers" , "tulips"]

    def read_and_decode(filename, resize_dims):
      img_bytes = tf.io.read_file(filename)
      img = tf.image.decode_jpeg(img_bytes , channels=IMG_CHANNELS)
      img = tf.image.convert_image_dtype(img , tf.float32)
      img = tf.image.resize(img , resize_dims)
      return img

    def parse_csvline(csv_line):
      record_defaults = ["" , ""]
      filename , label_string = tf.io.decode_csv(csv_line , record_defaults)
      img = read_and_decode(filename , [IMG_HEIGHT , IMG_WIDTH])
      label = tf.where(tf.equal(CLASS_NAMES, label_string))[0, 0]
      return img , label

    train_dataset = (
        tf.data.TextLineDataset("gs://cloud-ml-data/img/flower_photos/train_set.csv")
        .skip(1)
        .map(parse_csvline , num_parallel_calls=tf.data.experimental.AUTOTUNE)
        .batch(config.batch_size)
        .prefetch(tf.data.experimental.AUTOTUNE)
    )

    eval_dataset = (
        tf.data.TextLineDataset("gs://cloud-ml-data/img/flower_photos/train_set.csv")
        .skip(1)
        .map(parse_csvline , num_parallel_calls=tf.data.experimental.AUTOTUNE)
        .batch(config.batch_size)
        .prefetch(tf.data.experimental.AUTOTUNE)
    )

    model = keras.Sequential([
        keras.layers.Flatten(input_shape=(IMG_HEIGHT , IMG_WIDTH , IMG_CHANNELS)),
        keras.layers.Dense(config.hidden_nodes , activation="relu"),
        keras.layers.Dense(len(CLASS_NAMES) , activation = "softmax")
    ])

    model.compile(
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),
        loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
        metrics = ['accuracy']
    )

    model.fit(
        train_dataset,
        validation_data = eval_dataset,
        epochs = config.epochs,
        callbacks = [WandbMetricsLogger(log_freq=5)]
    )

wandb.agent(sweep_id , function = train)

