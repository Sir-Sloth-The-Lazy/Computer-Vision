# üëÅÔ∏è Visionary Realm: The Computer Vision Odyssey

Welcome to the **Visionary Realm**, a repository documenting the evolution of Computer Vision. This project traces the path from the earliest shallow networks to the cutting-edge Vision-Language Models (VLMs) that power today's AI breakthroughs.

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://tensorflow.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-Latest-ee4c2c.svg)](https://pytorch.org/)
[![Vision](https://img.shields.io/badge/Focus-Computer%20Vision-green.svg)](#)

---

## üöÄ The Roadmap

This repository is structured as a conceptual journey through the field of CV. Whether you're starting with pixels or prompting VLMs, you'll find it here.

### ü•â Phase 1: The Foundations (Classical)

Understanding the basics of image representation and simple classification.

- **Linear Neural Networks**: The humble beginnings of image processing.
- **Shallow Architectures**: Multi-layer perceptrons (MLPs) for basic pattern recognition.
- **Feature Engineering**: The era before deep learning took over.

### ü•à Phase 2: The CNN Era (Deep Learning Dominance)

Exploring the power of spatial hierarchies and convolutional kernels.

- **Classic CNNs**: LeNet, AlexNet, VGG.
- **Residual Connections**: ResNets and the art of training deep networks.
- **Efficient Nets**: Balancing performance and compute (MobileNet, EfficientNet).

### ü•á Phase 3: The Transformer Revolution

When Attention became the only thing you needed.

- **Vision Transformers (ViTs)**: Breaking images into patches.
- **Swin Transformers**: Hierarchical vision transformers via shifted windows.
- **Tokenization**: Reaching SOTA without convolutions.

### üåå Phase 4: The New Frontier (VLMs & Generative)

The intersection of Vision and Language.

- **Vision-Language Models (VLMs)**: CLIP, ALIGN, and zero-shot capabilities.
- **Multi-modal Giants**: Integrating vision into LLMs (LLaVA, MiniGPT-4).
- **Generative CV**: Diffusion models and visual creation.

---

## üõ†Ô∏è Tech Stack & Tools

- **Frameworks**: TensorFlow, Keras, PyTorch.
- **Libraries**: OpenCV, PIL, Scikit-Image, Matplotlib.
- **Optimization**: Weights & Biases for experiment tracking.

---

## üìÇ Current Repository Structure

| File                         | Description                                               |
| :--------------------------- | :-------------------------------------------------------- |
| `linear_nn_for_images.py`    | Implementation of baseline linear models for image tasks. |
| `shallow_neural_network_...` | A gateway into image classification using shallow layers. |
| `weights&biases.py`          | Experiment tracking integration scripts.                  |

_More advanced models (ViTs, Swin, VLMs) are currently being added!_

---

## üö¶ Getting Started

1. **Clone the repository**:
   ```bash
   git clone https://github.com/sirsloththelazy/ComputerVision.git
   ```
2. **Setup Environment**:
   ```bash
   pip install tensorflow matplotlib opencv-python wandb
   ```
3. **Run a Basic Model**:
   ```bash
   python shallow_neural_network_for_imageclassification.py
   ```

---

## üß† Why This Project?

Computer Vision isn't just about labels; it's about teaching machines to _perceive_. This repository serves as a personal laboratory and a learning guide for anyone looking to master the visual world, one layer at a time.

**Stay tuned as we move from shallow nets to the multi-modal future!** üöÄ
